<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
    <link rel="stylesheet" href="style.css">
    <link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'>
    <title>Project | EDA, ML & Optimization</title>
</head>
<body style="background-color:#f5f5f5">
    
    <div class="d-flex h-100 align-items-center justify-content-start">
        <div class="main-style">
            
                    <h1 class="display-1" class="lead">Complexity vs Insufficient Data</h1>
                    <h4 class="display-4 left">Objectives</h4>
                    <p> Training machine learning models that perform well has become increasingly easier. 
                        However, there is a lot more to take into account when attempting to do so, than just fitting them and predicting. In this project
                        we deal with a dataset that will pose problems for classic classifiers (and surely for much more sofisticated ones as well), 
                        with the aim of explaining why these methods don't work as well as we'd like. As a main takeaway is the idea that understanding the data,
                        what problem are we trying to solve, and which methods are adequate for the task, is paramount before engaging in ML modeling. Failure to
                        understand this could mean executing algorithms that take several hours to run in exchange for very low performance in terms both of results
                        and computational efficiency, or even trying and failing repeatedly to solve a problem that is actually unsolvable with the available data.  
                    </p>  
                    <h4 class="display-4 left">Summary</h4>
                    <p> We will use data from more than 70,000 beer recipes, which are segmented in 176 different styles. Beer styles will be our labels for 
                        classification, and we will deal with 2 subsets of the data: the first one will contain beer styles that amount for at least 0.5% of
                        total samples, and the second one will contain only the 2 most popular beer styles, making the classification task much simpler. The first 
                        dataset could be considered to be "complex" due to the high number of labels and high number of observations. Nonetheless, it should be
                        considered instead as "insufficient" data. In order to classify a large number of classes, it is not enough to have large samples of course,
                        but also a sufficient number of features (variables that describe each observation) that help distinguish classes between themselves, and hence
                        these must also be informative. In other words, the information in the data must contain enough different patterns so that ML methods can actually 
                        recognize them. This is difficult to know formally before testing any algorithm, but we should have an intuition to roughly identify datasets that will cause
                        problems. This is the case with our dataset and we will explain why later on. 
                    </p>
                        
                    <p>     
                        First, we have an exploratory data analysis to understand the data, and then we show the difference between both datasets 
                        with hyperparameter optimization methods to have the best fit possible on the classifiers, as proof that often data is the problem instead
                        of the model.
                    </p>  
            <hr>
                   
            
        </div>  
    </div>
    
     <div class="d-flex h-100 align-items-center justify-content-start">
        <div class="main-style">
                    
                    <h3 class="display-3 left">Exploratory Data Analysis</h3>
                    <p>The original data contains 73,861 observations (beer recipes) with 21 features (characteristics of the observations) segmented 
                        in 176 classes (beer styles). From this data we will make two subsets. Dataset-1 will be selected by keeping only the classes that represent at least
                        0.5% of data (in order to be able to stratify in the cross-validation methods) and Dataset-2 will be selected by keeping only the two largest classes.
                        Moreover, we apply a filter on the selected classes on the 'Sugar Scale' variable to keep only the larger class in this feature, since it is highly 
                        unbalanced. After selecting the data and applying the filter, we have 53,753 observations and 47 classes in Dataset-1 and 18,405 observations and 2 
                        classes for Dataset-2.
                        
                    <figure>
                        <img src="ML-data-exp/ml-exp/img/samples.png" class="img-fluid" alt="Responsive image">
                        <img src="ML-data-exp/ml-exp/img/samples2.png" class="img-fluid" alt="Responsive image">
                        <figcaption>Distribution of beer styles in Dataset-1 and Dataset-2 respectively.</figcaption>
                    </figure>
                        
                        
                    </p>
            
                    <p> To clean the data, we simply dropped the columns (features) that had too many missing values or that were irrelevant for the classification 
                        task. For example, the amount of beer made in the recipe tells us no information about what style the recipe belongs to. The rows
                        with missing values after keeping the most relevant features were dropped as well. The reason for not imputing is that we are interested 
                        in using this data for experimentation on machine learning modeling, rather than trying to extract patterns for a practical application. 
                        Also, Original Gravity and Final Gravity are highly correlated, so one of them was dropped.
                             
                    </p>
            
                    <p> A good way of understanding the intricacies of the beer styles represented in the recipe samples, is the following dendrogram, since it
                        provides a way of quickly visualizing similarity between beer styles of interest. This was made by taking the beer styles as vectors
                        on euclidean space described by the mean of the feature for each class corresponding to each entry. Then, single-linkage hierarchical clustering
                        with euclidean metrics was applied.  
                    <figure>
                        <img src="ML-data-exp/ml-exp/img/dendro.png" class="img-fluid" alt="Responsive image">
                        <figcaption>Dendrogram of beer styles (Dataset-1). The closer the connection of beerstyles to 0 on the X axis, the more similar they are.
                        Labels are colored according to a uniform 4-partition of the 'Color' feature range.</figcaption>
                    </figure>
                    </p>
            
                    <p> To show the difficulty of this classification task, due to the fact that there is simply not much data to help distinguish between classes, 
                        we illustrate the overlap between the Dataset-2 (binary) classes on the features that were kept with their pairwise (2D) projections.
                        
                    <figure>
                        <img src="ML-data-exp/ml-exp/img/pairs2.png" class="img-fluid" alt="Responsive image">
                        <figcaption>Pairwise projections of the Dataset-2 classes.</figcaption>
                    </figure>
                        
                        
                    </p>
            
                    <p> Moreover, we show how similar distributions between classes are when it comes to variables that usually makes beer styles somewhat 
                        different for the consumer: alcohol content and color.
                        
                    <figure>
                        <img src="ML-data-exp/ml-exp/img/abvdist.png" class="img-fluid" alt="Responsive image">
                        <img src="ML-data-exp/ml-exp/img/colordist.png" class="img-fluid" alt="Responsive image">
                        <figcaption>Pairwise projections of the Dataset-2 classes.</figcaption>
                    </figure>
                        
                        
                    </p>
            
                    <hr>
                    
        </div>  
    </div>
   
   <div class="d-flex h-100 align-items-center justify-content-center">
          <div class="main-style">
                      <h3 class="display-3 left">Performance</h3>
                      <p> For all the methods tested, we use hyperparameter optimization to show that the accuracy is bounded
                          not by model complexity or efficiency but by the data itself. This is the part where it becomes clear
                          that at some stage it becomes pointless to try and apply more complex machine learning models to the problem at hand.
                      </p>
                      <h4 class="display-4 left">Linear Classifiers</h4>
                      <p>Formally speaking, the Stochastic Gradient Descent method is an optimization algorithm (it seeks to minimize some function) and not per se 
                          a model for classification. However, scikit learn's SGDClassifier is an instance in which we can select hyperparameters that will yield
                          a classification model as a particular case. Since we are using hyperparameter optimization tools, we might as well select this method
                          first. In general, what linear classifiers do is try to segment the space the data is embedded in, into regions that will correspond to the 
                          classes in our task, using lines, planes or hyperplanes as separators. For Dataset-1, we have only 7 features for 47 different classes. 
                          That could be enought provided that the data is
                          very clearly separated in space, which is not the case in this example, as we can see from the pairwise projection plots 
                          (of the simplified
                          Dataset-2) above.
                      <h4 class="display-4 left">Non-linear Support Vector Machines</h4>
                      <p>Roughly speaking, what suppor vector machines do is find hyperplanes in space that separate datapoints into regions associated with classes, very much like 
                         linear classifiers, except that this regions are found in the space resulting form applying a non-linear transformation to the original 
                          data feature space (if a SVM has a linear kernel, then it is a linear classifier).
                           
                      </p>
                      <h4 class="display-4 left">Neural Networks</h4>
                      </p>
                      <hr>
          </div>
    </div>
    
    
    
    
    
    
    
</body>
</html>
